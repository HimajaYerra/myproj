{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from wavenet.utils import make_batch\n",
    "#from wavenet.models import Model, Generator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('overnight_all_compressed.npz')\n",
    "eval_data = data['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=eval_data[:,1]\n",
    "Y_train=eval_data[:,2]\n",
    "l= len(X_train)\n",
    "Xtrain = X_train[:round(l*0.7)]\n",
    "Xtest = X_train[round(l*0.7)+1:]\n",
    "ytrain = Y_train[:round(l*0.7)]\n",
    "ytest = Y_train[round(l*0.7)+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self,\n",
    "                 num_time_samples,\n",
    "                 num_channels=1,\n",
    "                 num_classes=256,\n",
    "                 num_blocks=2,\n",
    "                 num_layers=14,\n",
    "                 num_hidden=128,\n",
    "                 ):\n",
    "        \n",
    "        self.num_time_samples = num_time_samples\n",
    "        self.num_channels = num_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        \n",
    "       # inputs = tf.placeholder(tf.float64,\n",
    "                                #shape=(None, num_time_samples, num_channels))\n",
    "        #targets = tf.placeholder(tf.float64, shape=(None, num_time_samples))\n",
    "\n",
    "        h = inputs\n",
    "        hs = []\n",
    "        for b in range(num_blocks):\n",
    "            for i in range(num_layers):\n",
    "                rate = 2**i\n",
    "                h = dilated_conv1d(h, num_hidden, rate=rate)\n",
    "                print(h)\n",
    "                hs.append(h)\n",
    "\n",
    "        outputs = conv1d(h,\n",
    "                         num_classes,\n",
    "                         filter_width=1,\n",
    "                         gain=1.0,\n",
    "                         activation=None,\n",
    "                         bias=True)\n",
    "\n",
    "        costs = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            outputs, targets)\n",
    "        cost = tf.reduce_mean(costs)\n",
    "\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "        gpu_options = tf.GPUOptions(\n",
    "            per_process_gpu_memory_fraction=gpu_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.outputs = outputs\n",
    "        self.hs = hs\n",
    "        self.costs = costs\n",
    "        self.cost = cost\n",
    "        self.train_step = train_step\n",
    "        self.sess = sess\n",
    "\n",
    "    def _train(self, inputs, targets):\n",
    "        feed_dict = {self.inputs: inputs, self.targets: targets}\n",
    "        cost, _ = self.sess.run(\n",
    "            [self.cost, self.train_step],\n",
    "            feed_dict=feed_dict)\n",
    "        return cost\n",
    "\n",
    "    def train(self, inputs, targets):\n",
    "        losses = []\n",
    "        terminal = False\n",
    "        i = 0\n",
    "        while not terminal:\n",
    "            i += 1\n",
    "            cost = self._train(inputs, targets)\n",
    "            if cost < 1e-1:\n",
    "                terminal = True\n",
    "            losses.append(cost)\n",
    "            if i % 50 == 0:\n",
    "                plt.plot(losses)\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "def dilated_conv1d(inputs,\n",
    "                   out_channels,\n",
    "                   filter_width=2,\n",
    "                   rate=1,\n",
    "                   padding='VALID',\n",
    "                   gain=np.sqrt(2),\n",
    "                   activation=tf.nn.relu):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "      inputs: (tensor)\n",
    "      output_channels:\n",
    "      filter_width:\n",
    "      rate:\n",
    "      padding:\n",
    "      name:\n",
    "      gain:\n",
    "      activation:\n",
    "\n",
    "    Outputs:\n",
    "      outputs: (tensor)\n",
    "    '''\n",
    "    \n",
    "    #with tf.variable_scope(name):\n",
    "    _, width, _ = inputs.get_shape().as_list()\n",
    "    inputs_ = time_to_batch(inputs, rate=rate)\n",
    "    outputs_ = conv1d(inputs_,\n",
    "                      out_channels=out_channels,\n",
    "                      filter_width=filter_width,\n",
    "                      padding=padding,\n",
    "                      gain=gain,\n",
    "                      activation=activation)\n",
    "    _, conv_out_width, _ = outputs_.get_shape().as_list()\n",
    "    new_width = conv_out_width * rate\n",
    "    diff = new_width - width\n",
    "    outputs = batch_to_time(outputs_, rate=rate, crop_left=diff)\n",
    "\n",
    "    # Add additional shape information.\n",
    "    tensor_shape = [tf.Dimension(None),\n",
    "                    tf.Dimension(width),\n",
    "                    tf.Dimension(out_channels)]\n",
    "    outputs.set_shape(tf.TensorShape(tensor_shape))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10806, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1000\n",
    "leftover = len(Xtrain)%window_size\n",
    "\n",
    "X_reshaped_train=(Xtrain[:-leftover]).reshape(-1,window_size,1)\n",
    "print(X_reshaped_train.shape)\n",
    "\n",
    "y_reshaped_train=(ytrain[:-leftover]).reshape(-1,window_size,1)\n",
    "\n",
    "leftover_test = len(Xtest)%window_size\n",
    "\n",
    "X_reshaped_test=(Xtest[:-leftover_test]).reshape(-1,window_size,1)\n",
    "y_reshaped_test=(ytest[:-leftover_test]).reshape(-1,window_size,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-32367d9584c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m model = Model(num_time_samples=num_time_samples,\n\u001b[1;32m----> 7\u001b[1;33m               num_channels=num_channels)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m44100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-64c2163edcc5>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_time_samples, num_channels, num_classes, num_blocks, num_layers, num_hidden)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdilated_conv1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-be5b224d25d8>\u001b[0m in \u001b[0;36mdilated_conv1d\u001b[1;34m(inputs, out_channels, filter_width, rate, padding, gain, activation)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#with tf.variable_scope(name):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0minputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_to_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     outputs_ = conv1d(inputs_,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "inputs, targets = X_reshaped_train,y_reshaped_train\n",
    "num_time_samples = inputs.shape[1]\n",
    "num_channels = 1\n",
    "#gpu_fraction = 1.0\n",
    "\n",
    "model = Model(num_time_samples=num_time_samples,\n",
    "              num_channels=num_channels)\n",
    "\n",
    "Audio(inputs.reshape(inputs.shape[1]), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
